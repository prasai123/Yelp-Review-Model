{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "collapsed": true
   },
   "source": [
    "Sentiment Analysis on Yelp Reviews:\n",
    "\n",
    "Dataset Information: <br>\n",
    "(1). Dataset:\n",
    "    *   Column 1 - Unique Business ID\n",
    "    *   Column 2 - Date of Review\n",
    "    *   Column 3 - Review ID\n",
    "    *   Column 4 - Stars given by the user\n",
    "    *   Column 5 - Review given by the user\n",
    "    *   Column 6 - Type of text entered - Review\n",
    "    *   Column 7 - Unique User ID\n",
    "    *   Column 8 - Cool column: The number of cool votes the review received\n",
    "    *   Column 9 - Useful column: The number of useful votes the review received\n",
    "    *   Column 10 - Funny Column: The number of funny votes the review received <br>\n",
    "(2). Number of entries - 51000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# IMPORTING ALL THE NECESSARY LIBRARIES AND PACKAGES\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import math\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, roc_auc_score, roc_curve\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1eaa689d053a6fb89bbb697663821fa6a9788aa2"
   },
   "outputs": [],
   "source": [
    "# LOADING THE DATASET AND SEEING THE DETAILS\n",
    "data = pd.read_csv('../input/yelp.csv')\n",
    "# SHAPE OF THE DATASET\n",
    "print(\"Shape of the dataset:\")\n",
    "print(data.shape)\n",
    "# COLUMN NAMES\n",
    "print(\"Column names:\")\n",
    "print(data.columns)\n",
    "# DATATYPE OF EACH COLUMN\n",
    "print(\"Datatype of each column:\")\n",
    "print(data.dtypes)\n",
    "# SEEING FEW OF THE ENTRIES\n",
    "print(\"Few dataset entries:\")\n",
    "print(data.head())\n",
    "# DATASET SUMMARY\n",
    "data.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c74e401bf74f0a0a2cd7f05a57e99f6f0d4fefff"
   },
   "outputs": [],
   "source": [
    "#CREATING A NEW COLUMN IN THE DATASET FOR THE NUMBER OF WORDS IN THE REVIEW\n",
    "data['length'] = data['text'].apply(len)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d8d798fb8a33267eef690ebf3d6e289076300364"
   },
   "outputs": [],
   "source": [
    "#Visualization: To find if there is any correlation between stars and length of the review\n",
    "# COMPARING TEXT LENGTH TO STARS\n",
    "graph = sns.FacetGrid(data=data,col='stars')\n",
    "graph.map(plt.hist,'length',bins=50,color='blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0d33fbaf7bf9c99437ecc8ce8f3da33e017685d2"
   },
   "outputs": [],
   "source": [
    "\n",
    "# GETTING THE MEAN VALUES OF THE VOTE COLUMNS WRT THE STARS ON THE REVIEW\n",
    "stval = data.groupby('stars').mean()\n",
    "stval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2b4a85469a460276be7c113d917515979b27ceae"
   },
   "outputs": [],
   "source": [
    "# FINDING THE CORRELATION BETWEEN THE VOTE COLUMNS\n",
    "stval.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e25c839d200a3afc82f3eff86ace27a9ba700b6"
   },
   "source": [
    "From the observations,there is negative correlation between:\n",
    "    * Cool and Useful\n",
    "    * Cool and Funny\n",
    "    * Cool and Length  \n",
    "    \n",
    "Hence we can say that the reviews marked cool are not very cool, not very useful to others and short.<br>\n",
    "Whereas, there is a positive correlation between:\n",
    "    * Funny and Useful    \n",
    "    * Funny and Length\n",
    "    * Useful and Length    \n",
    "Thus, we can say that longer reviews tend to be funny and useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6bdff07af1a991b91e699eb1dddeedaec1894a38"
   },
   "outputs": [],
   "source": [
    "# CLASSIFICATION\n",
    "#Classifying the dataset and splitting it into the reviews and stars:\n",
    "data_classes = data[(data['stars']==1) | (data['stars']==3) | (data['stars']==5)]\n",
    "data_classes.head()\n",
    "print(data_classes.shape)\n",
    "\n",
    "# Seperate the dataset into X and Y for prediction\n",
    "x = data_classes['text']\n",
    "y = data_classes['stars']\n",
    "print(x.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0412473cc8b5458282c0bed7b6702763e9e0d4bc",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#defining a function which will clean the dataset by removing stopwords and punctuations.\n",
    "# CLEANING THE REVIEWS - REMOVAL OF STOPWORDS AND PUNCTUATION\n",
    "def text_process(text):\n",
    "    nopunc = [char for char in text if char not in string.punctuation]\n",
    "    nopunc = ''.join(nopunc)\n",
    "    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b4d9c7dd415b17a37428803a64f9a629ea546fd3",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CONVERTING THE WORDS INTO A VECTOR\n",
    "vocab = CountVectorizer(analyzer=text_process).fit(x)\n",
    "print(len(vocab.vocabulary_))\n",
    "r0 = x[0]\n",
    "print(r0)\n",
    "vocab0 = vocab.transform([r0])\n",
    "print(vocab0)\n",
    "\"\"\"\n",
    "    Now the words in the review number 78 have been converted into a vector.\n",
    "    The data that we can see is the transformed words.\n",
    "    If we now get the feature's name - we can get the word back!\n",
    "\"\"\"\n",
    "print(\"Getting the words back:\")\n",
    "print(vocab.get_feature_names()[19648])\n",
    "print(vocab.get_feature_names()[10643])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "fd0230355f93564ff0d66179f047827b594a1f36",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Vectorization of the whole review set and and checking the sparse matrix\n",
    "x = vocab.transform(x)\n",
    "#Shape of the matrix:\n",
    "print(\"Shape of the sparse matrix: \", x.shape)\n",
    "#Non-zero occurences:\n",
    "print(\"Non-Zero occurences: \",x.nnz)\n",
    "\n",
    "# DENSITY OF THE MATRIX\n",
    "density = (x.nnz/(x.shape[0]*x.shape[1]))*100\n",
    "print(\"Density of the matrix = \",density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "03cfa07d6a627b72c78b904eac2b6b428459b5c8",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SPLITTING THE DATASET INTO TRAINING SET AND TESTING SET\n",
    "x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c11143ea96a27b2fcf4f4b358b20b2214c853903"
   },
   "source": [
    "\n",
    "We will now use multiple Machine Algorithms to see which gives the best performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6f7541a4cb37736208028acf340a99065cccad92"
   },
   "source": [
    "(1). Multinomial Naive Bayes - We are using Multinomial Naive Bayes over Gaussian because with sparse data, Gaussian Naive Bayes assumptions aren't met and a simple gaussian fit over the data will not give us a good fit or prediction!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0bd46fa6e86db8c9aa27b8ff21f142cbd33c1322",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Multinomial Naive Bayes\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnb = MultinomialNB()\n",
    "mnb.fit(x_train,y_train)\n",
    "predmnb = mnb.predict(x_test)\n",
    "print(\"Confusion Matrix for Multinomial Naive Bayes:\")\n",
    "print(confusion_matrix(y_test,predmnb))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmnb)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predmnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "dfe152bbbedee29cea92e80a0796cff143f68cfe"
   },
   "source": [
    "(2). Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f47f04199e86368eea7bcb89dacf6ee3e36eb32b",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rmfr = RandomForestClassifier()\n",
    "rmfr.fit(x_train,y_train)\n",
    "predrmfr = rmfr.predict(x_test)\n",
    "print(\"Confusion Matrix for Random Forest Classifier:\")\n",
    "print(confusion_matrix(y_test,predrmfr))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predrmfr)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predrmfr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "9dd89695b2dfdac56ec21f565f2e04e427a94b78"
   },
   "source": [
    "(3). Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1667c0c25fdb50872b68d7c03e6a9cc7c3cd959d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train,y_train)\n",
    "preddt = dt.predict(x_test)\n",
    "print(\"Confusion Matrix for Decision Tree:\")\n",
    "print(confusion_matrix(y_test,preddt))\n",
    "print(\"Score:\",round(accuracy_score(y_test,preddt)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,preddt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "30b9fe08af4cbd989fe6ef3a21d156d6caf2b2af"
   },
   "source": [
    "(4). Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ef00d05e7aebf2fa0f56f5e58c5f32ef5ebd92e2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Support Vector Machine\n",
    "from sklearn.svm import SVC\n",
    "svm = SVC(random_state=101)\n",
    "svm.fit(x_train,y_train)\n",
    "predsvm = svm.predict(x_test)\n",
    "print(\"Confusion Matrix for Support Vector Machines:\")\n",
    "print(confusion_matrix(y_test,predsvm))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predsvm)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predsvm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "7d6b32501847725e3163d0fd9441d44c800b5173"
   },
   "source": [
    "(5). Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b2a4d2c63064a019729c476df7923be2daa17202",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting Classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\"\"\"# parameter evaluation\n",
    "gbe = GradientBoostingClassifier(random_state=0)\n",
    "parameters = {\n",
    "     'learning_rate': [0.05, 0.1, 0.5],\n",
    "    'max_features': [0.5, 1],\n",
    "    'max_depth': [3, 4, 5]}\n",
    "gridsearch=GridSearchCV(gbe,parameters,cv=100,scoring='roc_auc')\n",
    "gridsearch.fit(x,y)\n",
    "print(gridsearch.best_params_)\n",
    "print(gridsearch.best_score_)\"\"\"\n",
    "#Boosting\n",
    "gbi = GradientBoostingClassifier(learning_rate=0.1,max_depth=5,max_features=0.5,random_state=999999)\n",
    "gbi.fit(x_train,y_train)\n",
    "predgbi = gbi.predict(x_test)\n",
    "print(\"Confusion Matrix for Gradient Boosting Classifier:\")\n",
    "print(confusion_matrix(y_test,predgbi))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predgbi)*100,2))\n",
    "print(\"Classification Report:\",classification_report(y_test,predgbi))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "c3ce676382c75eccbcfe605f0a0dd04a48053abc"
   },
   "source": [
    "In the above GBC code, parameter evaluation code is commented because it takes a lot of time for execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "5e9eb8e5158760e1bf3802b3367eb1186817a804"
   },
   "source": [
    "(6). K - Nearest Neighbor Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4121c390f2f1e4e099bf219b0f01be11f0a85d3d",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# K Nearest Neighbour Algorithm\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "knn.fit(x_train,y_train)\n",
    "predknn = knn.predict(x_test)\n",
    "print(\"Confusion Matrix for K Neighbors Classifier:\")\n",
    "print(confusion_matrix(y_test,predknn))\n",
    "print(\"Score: \",round(accuracy_score(y_test,predknn)*100,2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,predknn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f56bf490b885f9303b3d231a4531e00e49cd6b2a"
   },
   "source": [
    "(7). XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b79d5587fed38dc6fed549de0f6e1c2744f78cb2",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# XGBoost Classifier\n",
    "import xgboost\n",
    "from xgboost import XGBClassifier\n",
    "xgb = XGBClassifier()\n",
    "xgb.fit(x_train,y_train)\n",
    "predxgb = xgb.predict(x_test)\n",
    "print(\"Confusion Matrix for XGBoost Classifier:\")\n",
    "print(confusion_matrix(y_test,predxgb))\n",
    "print(\"Score: \",round(accuracy_score(y_test,predxgb)*100,2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,predxgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "485d33ad9d0dded433a4fc7cf05924256467db2f",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MULTILAYER PERCEPTRON CLASSIFIER\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp = MLPClassifier()\n",
    "mlp.fit(x_train,y_train)\n",
    "predmlp = mlp.predict(x_test)\n",
    "print(\"Confusion Matrix for Multilayer Perceptron Classifier:\")\n",
    "print(confusion_matrix(y_test,predmlp))\n",
    "print(\"Score:\",round(accuracy_score(y_test,predmlp)*100,2))\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test,predmlp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4fdf36796200d49cb226e0afc62d0e33906f3fd6"
   },
   "source": [
    "From the above algorithm modelling, we can see that: \n",
    "    *  Multilayer Perceptron = 77.57%\n",
    "    * Multinomial Naive Bayes = 76.94%\n",
    "    * Gradient Boosting Classifier = 73.87%\n",
    "    * XGBoost Classifier = 70.81%\n",
    "    * Random Forest Classifier = 67.57%\n",
    "    * Decision Tree = 65.5%\n",
    "    * K Neighbor Classifier = 61.35%\n",
    "    * Support Vector Machine  = 59.1%\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4d1750493932ab569709498cbaa290fc6f4a0a07"
   },
   "source": [
    "Since multilayer perceptron classifier has the best score, let us use it to predict a random positive review, a random average review and a random negative review!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7a0d19cac82fa69142ab0e6fbd9c1ac05c001d48",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# POSITIVE REVIEW\n",
    "pr = data['text'][0]\n",
    "print(pr)\n",
    "print(\"Actual Rating: \",data['stars'][0])\n",
    "pr_t = vocab.transform([pr])\n",
    "print(\"Predicted Rating:\")\n",
    "mlp.predict(pr_t)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bfb82ff1085c6af91635c34819c6287b25848a42",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AVERAGE REVIEW\n",
    "ar = data['text'][16]\n",
    "print(ar)\n",
    "print(\"Actual Rating: \",data['stars'][16])\n",
    "ar_t = vocab.transform([ar])\n",
    "print(\"Predicted Rating:\")\n",
    "mlp.predict(ar_t)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "feb2cfec74130318701c0d0197a632d9d266609c",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NEGATIVE REVIEW\n",
    "nr = data['text'][16]\n",
    "print(nr)\n",
    "print(\"Actual Rating: \",data['stars'][23])\n",
    "nr_t = vocab.transform([nr])\n",
    "print(\"Predicted Rating:\")\n",
    "mlp.predict(nr_t)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c74cde9c07113026bc8c033c6f36c3a71c6b42b"
   },
   "outputs": [],
   "source": [
    "count = data['stars'].value_counts()\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "26e1de99725f6763637d0290892afaa5233da179"
   },
   "source": [
    "From the above, we can see that predictions are biased towards positive reviews. We can see that the dataset has more positive reviews as compared to negative reviews. \n",
    "Thic can be fixed by normalizing the dataset to have equal number of reviews - thereby removing the bias. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
